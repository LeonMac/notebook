{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e05ff6-af4f-4b6d-8080-3ed237ba482e",
   "metadata": {},
   "source": [
    "# Study the nn.Embedding and nn.Linear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d1267-b0ba-4e00-8447-eddc0adb343b",
   "metadata": {},
   "source": [
    "https://medium.com/@gautam.e/what-is-nn-embedding-really-de038baadd24\n",
    "\n",
    "https://www.youtube.com/watch?v=XswEBzNgIYc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b399e462-1546-4008-93d2-4b2d44521fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ade98fa-58c0-4bc1-a98d-728c20ceecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdfd1b-9cac-4199-9500-c880c53705e6",
   "metadata": {},
   "source": [
    "## Check nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2689e5d-047a-44fa-a296-5cc104b20c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(num_embeddings=10, embedding_dim=4)\n",
    "optimizer = torch.optim.Adam(embedding_layer.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8d21e3-2d9e-4fc2-8827-695eff1bb4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc55a51f-d847-45eb-a910-7593e8890791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2753,  0.6012, -0.7758,  0.4877],\n",
       "        [-0.4799,  0.9522,  1.6895, -0.7348],\n",
       "        [ 1.0987, -0.0538, -0.6264, -1.1798],\n",
       "        [-0.2704,  0.8823, -0.6534, -0.2049],\n",
       "        [-0.7768,  0.1396,  0.5873, -1.7623],\n",
       "        [ 0.6802,  1.6255, -0.2280,  1.4884],\n",
       "        [ 0.1690,  2.7113, -0.1665, -0.8009],\n",
       "        [-0.0663,  0.2883, -1.2854, -0.0727],\n",
       "        [ 0.4348, -0.2138,  0.1903, -1.4876],\n",
       "        [-0.3714, -0.6321,  0.5146, -1.1418]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c6be0e-0c0a-4501-bf26-52d56d413655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3714, -0.6321,  0.5146, -1.1418])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight.data[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e9a64-d887-447b-b6fc-31b7e547a991",
   "metadata": {},
   "source": [
    "embedding_layer 只是一个look up table, 共有10个index（0~9），每个index对应一个vector (dim =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7df605c-140a-4f90-bf85-1ac35396dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[-0.2704,  0.8823, -0.6534, -0.2049],\n",
      "        [ 1.0987, -0.0538, -0.6264, -1.1798],\n",
      "        [ 0.2753,  0.6012, -0.7758,  0.4877]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor1 = torch.tensor([3,2,0], dtype=torch.long)\n",
    "result1 = embedding_layer(input_tensor1) # 取出第3,2,0个 embedding\n",
    "print(result1.shape)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c3a1ae4-a874-41a9-bb48-c7d2d4be9714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 4])\n",
      "tensor([[[-0.4799,  0.9522,  1.6895, -0.7348],\n",
      "         [-0.2704,  0.8823, -0.6534, -0.2049]],\n",
      "\n",
      "        [[ 0.2753,  0.6012, -0.7758,  0.4877],\n",
      "         [-0.4799,  0.9522,  1.6895, -0.7348]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor2 = torch.tensor([[1, 3], [0,1]], dtype=torch.long)\n",
    "result2 = embedding_layer(input_tensor2) # 取出第1,3 matrix，取出第0,1 个matrix，组成第二个matrix，两个matrix合并成2个2x4，即 2x2x4 的矩阵\n",
    "print(result2.shape)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e60cb-aee9-4c8b-8149-18066c1b19c3",
   "metadata": {},
   "source": [
    "## Now let us look at nn.Linear\n",
    "Embedding vs Linear ， definition-wise?\n",
    "An embedding is the same thing as a linear layer, but works differently in that it does a **lookup** instead of a matrix-vector multiplication.\n",
    "也就是说，nn.embedding是为了lookup而生的nn layer，普通的nn.Linear则是为了矩阵乘法使用的。\n",
    "搞这么两套，主要还是为了不同应用场景，导致的存储，运算效率不同\n",
    "\n",
    "https://www.youtube.com/watch?v=XswEBzNgIYc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a307b48-6855-4f45-8a42-5ca769dd0caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e005e09-1a71-4335-9ac1-b786e93668ee",
   "metadata": {},
   "source": [
    "### Why use an embedding when we have a linear layer?\n",
    "An embedding is an efficient alternative to a single linear layer when one has a large number of input features. \n",
    "This may happen in natural language processing (NLP) when one is working with text data or in some (language-like) tabular data that is treated as a bag-of-words (BoW). In such cases its also quite common to have the input data available as a sparse matrix (typically a result of an output from sklearn’s CountVectorizer of TfidfVectorizer as a sparse.scipy.csr_matrix) and it is memory-inefficent to convert that in to a dense matrix but really easy to access its non-zero elements and their positions directly instead (using the data and indices attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8862d95d-0713-4fdb-8b64-134b324522bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sparse matrix: This could be your training set\n",
    "X_train = csr_matrix(np.array([[1, 0, 1, 0],\n",
    "                               [0, 0, 1, 1],\n",
    "                               [1, 1, 1, 0]]))\n",
    "# Get one row: One sample in the training set\n",
    "row = X_train.getrow(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae2d19a-7aee-4de0-aa9b-f52b11d6709d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372dde0-e69e-44de-a71a-2eed2764732b",
   "metadata": {},
   "source": [
    "Now let’s pass the training example row through the linear layer and the embedding so that we get the same result in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7361191d-98ca-4979-ac59-9e78776db34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1443, -0.1548, -0.3186,  0.0693],\n",
      "        [ 0.4708, -0.4276,  0.4181,  0.3375],\n",
      "        [-0.4092,  0.4163, -0.4208, -0.0187]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "w_linear = nn.Linear(4,3,bias=False)\n",
    "print(w_linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa2d3c6-b952-4e48-9668-0ad640c5051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "row_dense = torch.FloatTensor(row.toarray())\n",
    "print(row_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46773209-2251-46ee-9053-7dfb64e991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_linear = w_linear (row_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52478c4a-4dc1-4676-b8db-7aa1f3163bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1743,  0.8889, -0.8300]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prob_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e081ed-a123-4a35-95d1-22b8e38f74ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1443,  0.4708, -0.4092],\n",
      "        [-0.1548, -0.4276,  0.4163],\n",
      "        [-0.3186,  0.4181, -0.4208],\n",
      "        [ 0.0693,  0.3375, -0.0187]])\n"
     ]
    }
   ],
   "source": [
    "w_embedding = nn.Embedding(4, 3).from_pretrained(w_linear.weight.T)\n",
    "print(w_embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b78bbf9-92bd-4952-8017-33248eb3a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1743,  0.8889, -0.8300])\n"
     ]
    }
   ],
   "source": [
    "print(w_embedding(torch.tensor(row.indices)).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00c197-4156-4cce-9169-b56ca86e9788",
   "metadata": {},
   "source": [
    "The outputs are the same. Yay! \n",
    "A couple of observations to keep in mind when you’re using this in your own nn.Module:\n",
    "\n",
    "1. The embedding weights and the linear layers weights are transposed to each other.\n",
    "2. The linear layer w_linear does the actual matrix vector multiplication and therefore needs the row to be converted to dense format. In contrast, w_embedding just needed the indices of row to do a lookup. Not only is this faster, but it’s also quite convenient with the scipy.sparse.indices attribute that is available for the sparse matrix!\n",
    "3. The embedding requires the sum(0). Don’t forget it!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
