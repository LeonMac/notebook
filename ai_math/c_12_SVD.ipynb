{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预备知识：关于矩阵的奇异值和SVD实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 在这个示例中，矩阵 A 是一个3x3的矩阵，但是由于它的行和列线性相关，因此它的秩为2，小于行数和列数中的较小者（3）。因此，这个矩阵会有多个非零奇异值。\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个3x3的非满秩矩阵\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# 计算奇异值分解\n",
    "U, S, V = np.linalg.svd(A)\n",
    "\n",
    "print(\"左奇异向量：\\n\", U)\n",
    "print(\"奇异值：\", S)\n",
    "print(\"右奇异向量：\\n\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config data\n",
    "N = 3  # num of SVD feature. either 2 or 3\n",
    "def generate_component_list(num):\n",
    "    component_list = [\"component_\" + str(i) for i in range(1, num + 1)]\n",
    "    return component_list\n",
    "    \n",
    "components_label = generate_component_list(N)\n",
    "print(components_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD做语义分析分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Python is popular in machine learning\",\n",
    "         \"Distributed system is important in big data analysis\",\n",
    "        \"Machine learning is theoretical foundation of data mining\",\n",
    "        \"Learning Python is fun\",\n",
    "        \"Playing soccer is fun\",\n",
    "        \"Many data scientists like playing soccer\",\n",
    "        \"Chinese men's soccer team failed again\",\n",
    "        \"Thirty two soccer teams enter World Cup finals\"]\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1, stop_words=\"english\")\n",
    "data = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "pd.DataFrame(data.toarray(), index=corpus, columns=vectorizer.get_feature_names_out()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Singular value decomposition and LSA\"\"\"\n",
    "\n",
    "model = TruncatedSVD(N) # 使用奇异值分解的方法，建立一个降维模型，参数2：指定要保留的主成分数量，即降维后的特征数量。\n",
    "data_n = model.fit_transform(data)  #将原始数据输入到 TruncatedSVD 模型中进行拟合和变换操作。这将返回降维后的数据 data_n，其中特征数量已经被减少到 2 维。\n",
    "\n",
    "# 对降维后的数据 data_n 进行归一化处理。Normalizer 是用来对数据进行归一化的类，参数 copy=False 表示对数据进行归一化时不会创建副本，而是直接在原始数据上进行操作。\n",
    "#.fit_transform() 方法将归一化操作应用于数据，并返回归一化后的数据 data_n。\n",
    "data_n = Normalizer(copy=False).fit_transform(data_n)\n",
    "\n",
    "#data_n 是经过降维和归一化处理后的数据，它是一个二维数组，\n",
    "#每行代表一个样本，每列代表一个特征。\n",
    "#本例降维操作将特征数量减少到了 2，所以 data_n 中每个样本都表示为一个包含两个特征值的向量。\n",
    "#在这种情况下，每个样本的2个特征可能代表数据中的某种抽象性质或潜在结构，这些特征是根据原始数据中的各种特征通过降维技术提取出来的。因此，data_n 中的每个样本可以看作是一个经过降维和归一化处理后的数据点，其具体意义可能与原始数据的特征不同，但仍然保留了数据的主要结构或关系。\n",
    "data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_n, index = corpus, columns = components_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2dim(data_n):\n",
    "    xs = data_n[:,0]\n",
    "    ys = data_n[:,1]\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    %matplotlib inline\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([-1, 2])\n",
    "    ax.set_ylim([-1, 2])\n",
    "    plt.scatter(xs, ys)\n",
    "    plt.xlabel('First principal component')\n",
    "    plt.ylabel('Second principal component')\n",
    "    plt.title('Plot of points agains LSA principal components')\n",
    "    plt.show()\n",
    "\n",
    "def plot_3dim(data_n):\n",
    "    from mpl_toolkits import mplot3d\n",
    "    # 假设 data_n 有三列数据\n",
    "    # 提取数据的三个维度\n",
    "    x = data_n[:, 0]\n",
    "    y = data_n[:, 1]\n",
    "    z = data_n[:, 2]\n",
    "    \n",
    "    # 创建一个三维图形对象\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # 绘制三维散点图\n",
    "    ax.scatter(x, y, z)\n",
    "    \n",
    "    # 设置坐标轴标签和标题\n",
    "    ax.set_xlabel('X Axis')\n",
    "    ax.set_ylabel('Y Axis')\n",
    "    ax.set_zlabel('Z Axis')\n",
    "    ax.set_title('3D Scatter Plot')\n",
    "    \n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N == 2:\n",
    "    plot_2dim(data_n)\n",
    "elif N == 3:\n",
    "    plot_3dim(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 data_n 有多于两列的数据\n",
    "# 进行 PCA 降维，保留前两个主成分\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data_n)\n",
    "\n",
    "# 绘制散点图\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1])\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second principal component')\n",
    "plt.title('Plot of points against first two PCA components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = numpy.asarray(numpy.asmatrix(data_n) * numpy.asmatrix(data_n).T)\n",
    "pd.DataFrame(similarity, index = corpus, columns = corpus).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(similarity,cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.components_,index=['component_1','component_2'],columns=vectorizer.get_feature_names_out()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
